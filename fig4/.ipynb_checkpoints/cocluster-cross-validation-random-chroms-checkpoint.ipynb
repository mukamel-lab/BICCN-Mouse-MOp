{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/cndd/fangming/CEMBA/snmcseq_dev')\n",
    "import importlib\n",
    "\n",
    "\n",
    "from __init__ import *\n",
    "from __init__jupyterlab import *\n",
    "from scipy import sparse\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import fbpca\n",
    "\n",
    "import snmcseq_utils\n",
    "importlib.reload(snmcseq_utils)\n",
    "import CEMBA_run_tsne\n",
    "import CEMBA_clst_utils\n",
    "import SCF_utils\n",
    "importlib.reload(SCF_utils)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# import seaborn as sns \n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfoldcv_scf_old(gxc_hvftrs_sub_g0, gxc_hvftrs_sub_g1, resolutions, k, \n",
    "                metas_sub, mods_selected, features_selected, settings,   \n",
    "                ps, drop_npcs,\n",
    "                cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "                npc,\n",
    "                output_pcX_all, output_cells_all, output_clst_and_umap,\n",
    "                reduce_dim=0,\n",
    "                nfolds=5, n_repeats=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    if os.path.isfile(output_clst_and_umap):\n",
    "        df_clsts = pd.read_csv(output_clst_and_umap, sep=\"\\t\", index_col=0)\n",
    "        \n",
    "    else:\n",
    "        # cluster on g0 with different resolutions\n",
    "        pcX_all, cells_all = SCF_utils.core_scf_routine(mods_selected, features_selected, settings, \n",
    "                                                        metas_sub, gxc_hvftrs_sub_g0, \n",
    "                                                        ps, drop_npcs,\n",
    "                                                        cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "                                                        npc,\n",
    "                                                        output_pcX_all, output_cells_all,\n",
    "                                                        )\n",
    "        df_clsts = SCF_utils.clustering_umap_routine(pcX_all, cells_all, mods_selected, metas_sub,\n",
    "                                                     resolutions, k, \n",
    "                                                     umap_neighbors, min_dist, # doesn't matter\n",
    "                                                     output_clst_and_umap,\n",
    "                                                     cluster_only=True,\n",
    "                                                     )\n",
    "    \n",
    "    # train and predict on g1\n",
    "    res_nclsts = []\n",
    "    res_mse_mean = {mod: [] for mod in mods_selected} \n",
    "    res_mse_se = {mod: [] for mod in mods_selected} \n",
    "    res_mse_t_mean = {mod: [] for mod in mods_selected} \n",
    "    res_mse_t_se = {mod: [] for mod in mods_selected}\n",
    "    kl = KFold(n_splits=nfolds)\n",
    "    \n",
    "    # test different resolution\n",
    "    for resolution in resolutions:\n",
    "        print(resolution, end='')\n",
    "        res_mse = {}\n",
    "        res_mse_t = {} \n",
    "\n",
    "        cluster_col = 'cluster_joint_r{}'.format(resolution)\n",
    "        df_clst = df_clsts[[cluster_col]].rename(columns={cluster_col: 'cluster'})\n",
    "        nclsts = len(df_clst['cluster'].unique())\n",
    "        res_nclsts.append(nclsts) # record number of clusters\n",
    "        cells_clst = df_clst['cluster'] # cell -> cluster label look up series\n",
    "        \n",
    "        # do it in every modality\n",
    "        for mod in mods_selected:\n",
    "            print(mod)\n",
    "            # set up\n",
    "            res_mse[mod] = []\n",
    "            res_mse_t[mod] = []\n",
    "            \n",
    "            metadata = metas_sub[mod].copy()\n",
    "            metadata['cluster_cv'] = df_clst.loc[metadata.index, 'cluster'] \n",
    "            gxc_hvftr = gxc_hvftrs_sub_g1[mod]\n",
    "            \n",
    "            if settings[mod].mod_category == 'mc':\n",
    "                assert np.all(metadata.index.values == gxc_hvftr.columns.values)\n",
    "                features_y = gxc_hvftr.T.values\n",
    "                if reduce_dim:\n",
    "                    U, s, Vt = fbpca.pca(features_y, k=reduce_dim)\n",
    "                    features_y = U.dot(np.diag(s))\n",
    "            else:\n",
    "                assert np.all(metadata.index.values == gxc_hvftr.cell)\n",
    "                features_y = pd.DataFrame(gxc_hvftr.data.T.todense(), \n",
    "                                          index=gxc_hvftr.cell, \n",
    "                                          columns=gxc_hvftr.gene).values\n",
    "                if reduce_dim:\n",
    "                    U, s, Vt = fbpca.pca(features_y, k=reduce_dim)\n",
    "                    features_y = U.dot(np.diag(s))\n",
    "                \n",
    "            ncells = len(metadata)\n",
    "            \n",
    "            for i_repeat in range(n_repeats):\n",
    "                print('.', end='')\n",
    "                \n",
    "                # shuffle data\n",
    "                cells_shuffled_idx = np.random.permutation(np.arange(ncells))\n",
    "                metadata = metadata.iloc[cells_shuffled_idx, :] \n",
    "                metadata['cell_idx'] = np.arange(ncells)\n",
    "                features_y = features_y[cells_shuffled_idx, :]\n",
    "                \n",
    "                # split training and test \n",
    "                for train_idx, test_idx in kl.split(np.arange(ncells)):\n",
    "                    # compute cluster centroids for training cells \n",
    "                    y_centroids = {}\n",
    "                    clsts_in_train = []\n",
    "                    for clst, df_sub in metadata.iloc[train_idx].groupby('cluster_cv'):\n",
    "                        cells_sub_idx = df_sub['cell_idx'].values\n",
    "                        y_centroids[clst] = features_y[cells_sub_idx, :].mean(axis=0)\n",
    "                        clsts_in_train.append(clst)\n",
    "                        \n",
    "                    # compute MSE for test cells\n",
    "                    mse = 0\n",
    "                    num_mse = 0\n",
    "                    num_umse = 0\n",
    "                    for j in test_idx: \n",
    "                        # cell idx j and cluster idx i\n",
    "                        cell_j = metadata.index.values[j]\n",
    "                        clst_i = cells_clst[cell_j]\n",
    "                        if clst_i in clsts_in_train:\n",
    "                            diff = features_y[j, :] - y_centroids[clst_i]\n",
    "                            mse += diff.dot(diff)\n",
    "                            num_mse += 1\n",
    "                        else:\n",
    "                            num_umse += 1 \n",
    "                    mse /= num_mse\n",
    "                    res_mse[mod].append(mse)\n",
    "\n",
    "                    # compute MSE for training cells \n",
    "                    mse = 0\n",
    "                    for j in train_idx: \n",
    "                        # cell idx j and cluster idx i\n",
    "                        cell_j = metadata.index.values[j]\n",
    "                        clst_i = cells_clst[cell_j]\n",
    "                        diff = features_y[j, :] - y_centroids[clst_i]\n",
    "                        mse += diff.dot(diff)\n",
    "                    mse /= len(train_idx) \n",
    "                    res_mse_t[mod].append(mse)\n",
    "                # end of n-fold training test for \n",
    "                # each collect 1 data point\n",
    "                \n",
    "            # end of n-repeats for\n",
    "            # summarize n-repeats into stats\n",
    "            res_mse[mod] = np.array(res_mse[mod])\n",
    "            \n",
    "            res_mse_mean[mod].append(res_mse[mod].mean())\n",
    "            res_mse_se[mod].append(1.96*res_mse[mod].std()/np.sqrt(nfolds))\n",
    "\n",
    "            res_mse_t[mod] = np.array(res_mse_t[mod])\n",
    "            res_mse_t_mean[mod].append(res_mse_t[mod].mean())\n",
    "            res_mse_t_se[mod].append(1.96*res_mse_t[mod].std()/np.sqrt(nfolds))\n",
    "            print('')\n",
    "#             break\n",
    "        # end of n-modality for \n",
    "        \n",
    "    # end of resolution for\n",
    "    res_nclsts = np.array(res_nclsts)\n",
    "    \n",
    "    for mod in mods_selected:\n",
    "        res_mse_mean[mod] = np.array(res_mse_mean[mod])\n",
    "        res_mse_se[mod] = np.array(res_mse_se[mod])\n",
    "        res_mse_t_mean[mod] = np.array(res_mse_t_mean[mod])\n",
    "        res_mse_t_se[mod] = np.array(res_mse_t_se[mod])\n",
    "\n",
    "    return ( \n",
    "         res_nclsts,\n",
    "         res_mse_mean, res_mse_se, \n",
    "         res_mse_t_mean, res_mse_t_se,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfoldcv_scf(gxc_hvftrs_sub_g0, gxc_hvftrs_sub_g1, resolutions, k, \n",
    "                metas_sub, mods_selected, features_selected, settings,   \n",
    "                ps, drop_npcs,\n",
    "                cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "                npc,\n",
    "                output_pcX_all, output_cells_all, output_clst_and_umap,\n",
    "                reduce_dim=0,\n",
    "                nfolds=5, n_repeats=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    if os.path.isfile(output_clst_and_umap):\n",
    "        df_clsts = pd.read_csv(output_clst_and_umap, sep=\"\\t\", index_col=0)\n",
    "        \n",
    "    else:\n",
    "        # cluster on g0 with different resolutions\n",
    "        pcX_all, cells_all = SCF_utils.core_scf_routine(mods_selected, features_selected, settings, \n",
    "                                                        metas_sub, gxc_hvftrs_sub_g0, \n",
    "                                                        ps, drop_npcs,\n",
    "                                                        cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "                                                        npc,\n",
    "                                                        output_pcX_all, output_cells_all,\n",
    "                                                        )\n",
    "        df_clsts = SCF_utils.clustering_umap_routine(pcX_all, cells_all, mods_selected, metas_sub,\n",
    "                                                     resolutions, k, \n",
    "                                                     umap_neighbors, min_dist, # doesn't matter\n",
    "                                                     output_clst_and_umap,\n",
    "                                                     cluster_only=True,\n",
    "                                                     )\n",
    "    \n",
    "    # train and predict on g1\n",
    "    res_nclsts = []\n",
    "    res_mse_mean = {mod: [] for mod in mods_selected} \n",
    "    res_mse_se = {mod: [] for mod in mods_selected} \n",
    "    res_mse_t_mean = {mod: [] for mod in mods_selected} \n",
    "    res_mse_t_se = {mod: [] for mod in mods_selected}\n",
    "    kl = KFold(n_splits=nfolds)\n",
    "    \n",
    "    # test different resolution\n",
    "    for resolution in resolutions:\n",
    "        print(resolution, end='')\n",
    "        res_mse = {}\n",
    "        res_mse_t = {} \n",
    "\n",
    "        cluster_col = 'cluster_joint_r{}'.format(resolution)\n",
    "        df_clst = df_clsts[[cluster_col]].rename(columns={cluster_col: 'cluster'})\n",
    "        nclsts = len(df_clst['cluster'].unique())\n",
    "        res_nclsts.append(nclsts) # record number of clusters\n",
    "        cells_clst = df_clst['cluster'] # cell -> cluster label look up series\n",
    "        \n",
    "        # do it in every modality\n",
    "        for mod in mods_selected:\n",
    "            print(mod)\n",
    "            # set up\n",
    "            res_mse[mod] = []\n",
    "            res_mse_t[mod] = []\n",
    "            \n",
    "            metadata = metas_sub[mod].copy()\n",
    "            metadata['cluster_cv'] = df_clst.loc[metadata.index, 'cluster'] \n",
    "            gxc_hvftr = gxc_hvftrs_sub_g1[mod]\n",
    "            \n",
    "            if settings[mod].mod_category == 'mc':\n",
    "                assert np.all(metadata.index.values == gxc_hvftr.columns.values)\n",
    "                features_y = gxc_hvftr.T.values\n",
    "                if reduce_dim:\n",
    "                    U, s, Vt = fbpca.pca(features_y, k=reduce_dim)\n",
    "                    features_y = U.dot(np.diag(s))\n",
    "            else:\n",
    "                assert np.all(metadata.index.values == gxc_hvftr.cell)\n",
    "                features_y = pd.DataFrame(gxc_hvftr.data.T.todense(), \n",
    "                                          index=gxc_hvftr.cell, \n",
    "                                          columns=gxc_hvftr.gene).values\n",
    "                if reduce_dim:\n",
    "                    U, s, Vt = fbpca.pca(features_y, k=reduce_dim)\n",
    "                    features_y = U.dot(np.diag(s))\n",
    "                \n",
    "            ncells = len(metadata)\n",
    "            \n",
    "            for i_repeat in range(n_repeats):\n",
    "                print('.', end='')\n",
    "                \n",
    "                # shuffle data\n",
    "                cells_shuffled_idx = np.random.permutation(np.arange(ncells))\n",
    "                metadata = metadata.iloc[cells_shuffled_idx, :] \n",
    "                metadata['cell_idx'] = np.arange(ncells)\n",
    "                features_y = features_y[cells_shuffled_idx, :]\n",
    "                \n",
    "                # split training and test \n",
    "                for train_idx, test_idx in kl.split(np.arange(ncells)):\n",
    "                    # compute cluster centroids for training cells \n",
    "                    metadata_train = metadata.iloc[train_idx]\n",
    "                    clsts_in_train = np.unique(metadata_train['cluster_cv'].values)\n",
    "                    clsts_not_in_train = np.unique(metadata['cluster_cv'].values).tolist()\n",
    "                    y_centroids = np.zeros((len(clsts_in_train), features_y.shape[1]))\n",
    "                    cluster_to_idx_lookup = {}\n",
    "                    for count_idx, (clst, df_sub) in enumerate(metadata_train.groupby('cluster_cv')):\n",
    "                        cells_sub_idx = df_sub['cell_idx'].values\n",
    "                        y_centroids[count_idx, :] = features_y[cells_sub_idx, :].mean(axis=0)\n",
    "                        cluster_to_idx_lookup[clst] = count_idx\n",
    "                        clsts_not_in_train.remove(clst)\n",
    "                    for clst in clsts_not_in_train:\n",
    "                        cluster_to_idx_lookup[clst] = -1\n",
    "                        \n",
    "                    # compute MSE for test cells\n",
    "                    cells_j = metadata.index.values[test_idx]\n",
    "                    clsts_i = cells_clst[cells_j]\n",
    "                    clsts_i_idx = np.array([cluster_to_idx_lookup[clst] for clst in clsts_i])\n",
    "                    cond = (clsts_i_idx != -1)  # test if clsts_i in clsts_in_train\n",
    "                    test_idx, cells_j, clsts_i, clsts_i_idx = test_idx[cond], cells_j[cond], clsts_i[cond], clsts_i_idx[cond]\n",
    "                    diff = features_y[test_idx, :] - y_centroids[clsts_i_idx, :]\n",
    "                    mse = (diff**2).sum(axis=1).mean()\n",
    "                    res_mse[mod].append(mse)\n",
    "\n",
    "                    # compute MSE for training cells \n",
    "                    cells_j = metadata.index.values[train_idx]\n",
    "                    clsts_i = cells_clst[cells_j]\n",
    "                    clsts_i_idx = np.array([cluster_to_idx_lookup[clst] for clst in clsts_i])\n",
    "                    diff = features_y[train_idx, :] - y_centroids[clsts_i_idx, :]\n",
    "                    mse = (diff**2).sum(axis=1).mean()\n",
    "                    res_mse_t[mod].append(mse)\n",
    "                    \n",
    "                # end of n-fold training test for \n",
    "                # each collect 1 data point\n",
    "                \n",
    "            # end of n-repeats for\n",
    "            # summarize n-repeats into stats\n",
    "            res_mse[mod] = np.array(res_mse[mod])\n",
    "            \n",
    "            res_mse_mean[mod].append(res_mse[mod].mean())\n",
    "            res_mse_se[mod].append(1.96*res_mse[mod].std()/np.sqrt(nfolds))\n",
    "\n",
    "            res_mse_t[mod] = np.array(res_mse_t[mod])\n",
    "            res_mse_t_mean[mod].append(res_mse_t[mod].mean())\n",
    "            res_mse_t_se[mod].append(1.96*res_mse_t[mod].std()/np.sqrt(nfolds))\n",
    "            print('')\n",
    "#             break\n",
    "        # end of n-modality for \n",
    "        \n",
    "    # end of resolution for\n",
    "    res_nclsts = np.array(res_nclsts)\n",
    "    \n",
    "    for mod in mods_selected:\n",
    "        res_mse_mean[mod] = np.array(res_mse_mean[mod])\n",
    "        res_mse_se[mod] = np.array(res_mse_se[mod])\n",
    "        res_mse_t_mean[mod] = np.array(res_mse_t_mean[mod])\n",
    "        res_mse_t_se[mod] = np.array(res_mse_t_se[mod])\n",
    "\n",
    "    return ( \n",
    "         res_nclsts,\n",
    "         res_mse_mean, res_mse_se, \n",
    "         res_mse_t_mean, res_mse_t_se,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utils\n",
    "def plot_errorbar_ax(ax, x, y, yerr, color='C0', label=''):\n",
    "    \"\"\"Plot a line with errorbar \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    yerr = np.array(yerr)\n",
    "    \n",
    "    ax.plot(x, y, '-o', \n",
    "           markersize=5,\n",
    "           color=color,\n",
    "           label=label,\n",
    "           )\n",
    "    ax.fill_between(x, y-yerr, y+yerr, \n",
    "                    color=color,\n",
    "                    alpha=0.3,\n",
    "                    zorder=0,\n",
    "                   )\n",
    "    return\n",
    "\n",
    "def plot_errorbar_fancymin_ax(ax, x, y, yerr, color='C0', label=''):\n",
    "    \"\"\"Plot a line with errorbar + min position and min-se position\n",
    "    \"\"\"\n",
    "    from scipy import optimize\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    yerr = np.array(yerr)\n",
    "\n",
    "    plot_errorbar_ax(ax, x, y, yerr, color=color, label=label)\n",
    "    \n",
    "    # get minimum and plot\n",
    "    min_arg = np.argmin(y)\n",
    "    min_x = x[min_arg]\n",
    "    min_y = y[min_arg]\n",
    "    ax.plot(min_x, min_y, '^',\n",
    "               markersize=12,\n",
    "               color=color,\n",
    "               )\n",
    "    \n",
    "    # get minimum + se and plot\n",
    "    f = lambda _x: np.interp(_x, x[:min_arg], (y-yerr)[:min_arg]) - min_y\n",
    "    try:\n",
    "        res_root = optimize.root_scalar(f, bracket=(1, min_x))\n",
    "        min_x_se = int(res_root.root+0.5)\n",
    "    except: \n",
    "        min_x_se = x[0]\n",
    "    ax.plot(min_x_se, min_y, 's', \n",
    "               markersize=10,\n",
    "               color=color,\n",
    "           )\n",
    "        \n",
    "    return int(min_x_se), int(min_x), min_y\n",
    "    \n",
    "def plot_bi_cv_ax(ax, x, y, yerr, color='C0', mod=\"\", ylabel=\"MSE +/- SEM Normalized\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    min_x_se, min_x, min_y = plot_errorbar_fancymin_ax(ax, x, y, yerr, color=color,)\n",
    "    ax.set_title(\"{}: {} - {}\".format(mod, min_x_se, min_x))\n",
    "    ax.set_ylabel(ylabel)\n",
    "    return\n",
    "\n",
    "def plot_bi_cv_subfig(ax, x1, y1, yerr1, y1_tr, yerr1_tr, color1, mod1,\n",
    "                    xlabel='Number of clusters',\n",
    "                    ylabel='MSE +/- SEM Normalized',\n",
    "                   ):\n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    \n",
    "    plot_errorbar_ax(ax, x1, y1_tr, yerr1_tr, color='black', label='Training error')\n",
    "    plot_bi_cv_ax(ax, x1, y1, yerr1, color=color1, mod=mod1, ylabel=ylabel)\n",
    "        \n",
    "    ax.set_xscale('log', basex=2)\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mop_cv_test_190710'\n",
    "outdir = '/cndd/fangming/CEMBA/data/MOp_all/results'\n",
    "output_results = outdir + '/cross_validation_results_{}.pkl'.format(name)\n",
    "output_pcX_all = outdir + '/pcX_all_{}.npy'.format(name)\n",
    "output_cells_all = outdir + '/cells_all_{}.npy'.format(name)\n",
    "output_clst_and_umap = outdir + '/intg_summary_{}.tsv'.format(name)\n",
    "\n",
    "output_figures = outdir + '/figures/{}_{{}}.{{}}'.format(name)\n",
    "# SAVE_KNN_MAT = True\n",
    "# output_knn_mat = outdir + '/knn_{}_{{}}_from_{{}}.npz'.format(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/cndd/fangming/CEMBA/data/MOp_all/organized_neurons_v6'\n",
    "\n",
    "# fixed dataset configs\n",
    "sys.path.insert(0, DATA_DIR)\n",
    "import __init__datasets\n",
    "importlib.reload(__init__datasets)\n",
    "from __init__datasets import *\n",
    "\n",
    "meta_f = os.path.join(DATA_DIR, '{0}_metadata.tsv')\n",
    "hvftrs_f = os.path.join(DATA_DIR, '{0}_hvfeatures.{1}')\n",
    "hvftrs_gene = os.path.join(DATA_DIR, '{0}_hvfeatures.gene')\n",
    "hvftrs_cell = os.path.join(DATA_DIR, '{0}_hvfeatures.cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_selected = [\n",
    "    'snmcseq_gene',\n",
    "#     'snatac_gene',\n",
    "    'smarter_cells',\n",
    "    'smarter_nuclei',\n",
    "#     '10x_cells', \n",
    "#     '10x_nuclei', \n",
    "#     '10x_cells_v3',\n",
    "#     '10x_nuclei_v3',\n",
    "#     '10x_nuclei_v3_Macosko',\n",
    "    ]\n",
    "\n",
    "# features_selected = ['10x_cells']\n",
    "features_selected = ['smarter_cells']\n",
    "# check features\n",
    "for features_modality in features_selected:\n",
    "    assert (features_modality in mods_selected)\n",
    "\n",
    "# within modality\n",
    "ps = {'mc': 0.9,\n",
    "      'atac': 0.1,\n",
    "      'rna': 0.7,\n",
    "     }\n",
    "drop_npcs = {'mc': 0,\n",
    "      'atac': 0,\n",
    "      'rna': 0,\n",
    "     }\n",
    "\n",
    "# across modality\n",
    "cross_mod_distance_measure = 'correlation' # cca\n",
    "knn = 20 \n",
    "relaxation = 3\n",
    "n_cca = 30\n",
    "\n",
    "# PCA\n",
    "npc = 50\n",
    "\n",
    "# clustering\n",
    "k = 30\n",
    "resolutions = [0.8, 1, 2, 4]\n",
    "# umap\n",
    "umap_neighbors = 60\n",
    "min_dist=min_dist = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = '/cndd/fangming/CEMBA/data/MOp_all/results/intg_summary_mop_9mods_v2_cv_190709_v2.tsv'\n",
    "# df_summary = pd.read_csv(f, sep='\\t')\n",
    "# print(df_summary.shape)\n",
    "# df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_summary), len(df_summary['sample'].unique()))\n",
    "# u, c = np.unique(df_summary['sample'].values, return_counts=True)\n",
    "# dup = u[c > 1]\n",
    "# print(len(dup))\n",
    "# df_summary[df_summary['sample'].isin(dup)].sort_values('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/10/2019 04:52:20 PM *\n"
     ]
    }
   ],
   "source": [
    "log = snmcseq_utils.create_logger()\n",
    "logging.info('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    27039\n",
      "0    24632\n",
      "Name: chr, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gene_name\n",
       "0610005C13Rik    1\n",
       "0610006L08Rik    1\n",
       "0610009B22Rik    1\n",
       "0610009E02Rik    0\n",
       "0610009L18Rik    1\n",
       "Name: chr, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gene chrome lookup\n",
    "chroms = np.arange(1, 20, 1).tolist() + ['X']\n",
    "chroms = ['chr'+str(chrom) for chrom in chroms]\n",
    "\n",
    "f = PATH_GENEBODY_ANNOTATION\n",
    "df_genes = pd.read_csv(f, sep=\"\\t\")\n",
    "gene_set_lookup = (df_genes[df_genes['chr'].isin(chroms)]\n",
    "                             .groupby('gene_name').first()['chr']\n",
    "                             .replace('chrX', 'chr20')\n",
    "                             .apply(lambda x: int(x[3:])%2)\n",
    "                    )\n",
    "print(gene_set_lookup.value_counts())\n",
    "gene_set_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snmcseq_gene (4936, 38)\n",
      "smarter_cells (6244, 11)\n",
      "smarter_nuclei (5911, 11)\n"
     ]
    }
   ],
   "source": [
    "metas = collections.OrderedDict()\n",
    "for mod in mods_selected:\n",
    "    metas[mod] = pd.read_csv(meta_f.format(mod), sep=\"\\t\").reset_index().set_index(settings[mod].cell_col)\n",
    "#     try:\n",
    "#         print(metas[mod].loc[dup])\n",
    "#     except:\n",
    "#         pass\n",
    "    print(mod, metas[mod].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snmcseq_gene\n",
      "(4830, 4936) 7.116071701049805\n",
      "smarter_cells\n",
      "(4176, 6244) 1.031461477279663\n",
      "smarter_nuclei\n",
      "(3809, 5911) 0.49759626388549805\n"
     ]
    }
   ],
   "source": [
    "gxc_hvftrs = collections.OrderedDict()\n",
    "for mod in mods_selected:\n",
    "    print(mod)\n",
    "    ti = time.time()\n",
    "    \n",
    "    if settings[mod].mod_category == 'mc':\n",
    "        f_mat = hvftrs_f.format(mod, 'tsv')\n",
    "        gxc_hvftrs[mod] = pd.read_csv(f_mat, sep='\\t', header=0, index_col=0) \n",
    "        gxc_hvftrs[mod].index = SCF_utils.standardize_gene_name(gxc_hvftrs[mod].index)  # standardize gene name \n",
    "        print(gxc_hvftrs[mod].shape, time.time()-ti)\n",
    "        assert np.all(gxc_hvftrs[mod].columns.values == metas[mod].index.values) # make sure cell name is in the sanme order as metas (important if save knn mat)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    f_mat = hvftrs_f.format(mod, 'npz')\n",
    "    f_gene = hvftrs_gene.format(mod)\n",
    "    f_cell = hvftrs_cell.format(mod)\n",
    "    _gxc_tmp = snmcseq_utils.load_gc_matrix(f_gene, f_cell, f_mat)\n",
    "    _gene = _gxc_tmp.gene\n",
    "    _cell = _gxc_tmp.cell\n",
    "    _mat = _gxc_tmp.data\n",
    "\n",
    "    _gene = SCF_utils.standardize_gene_name(_gene)  # standardize gene name  \n",
    "    \n",
    "#     ## remove duplicated genes (for now)\n",
    "#     u, c = np.unique(_gene, return_counts=True)\n",
    "#     dup = u[c > 1]\n",
    "#     uniq_bool = np.array([False if gene in dup else True for gene in _gene])\n",
    "#     _gene_selected = _gene[uniq_bool]\n",
    "#     _gene_selected_idx = np.arange(len(_gene))[uniq_bool]\n",
    "#     _gene = _gene_selected\n",
    "#     _mat = _mat.tocsr()[_gene_selected_idx, :]\n",
    "#     ## remove duplicated genes complete\n",
    "    \n",
    "    gxc_hvftrs[mod] = GC_matrix(_gene, _cell, _mat)\n",
    "    assert np.all(gxc_hvftrs[mod].cell == metas[mod].index.values) # make sure cell name is in the sanme order as metas (important if save knn mat)\n",
    "    print(gxc_hvftrs[mod].data.shape, time.time()-ti)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(mods_selected, metas, gxc_hvftrs, p):\n",
    "    \"\"\"\n",
    "    p - fraction of cells from each dataset to be included\n",
    "    \"\"\"\n",
    "    metas_sub = collections.OrderedDict()\n",
    "    gxc_hvftrs_sub = collections.OrderedDict()\n",
    "    for mod in mods_selected: \n",
    "        # subsample meta\n",
    "        cells_included = metas[mod].index.values[np.random.rand(len(metas[mod]))<p]\n",
    "        metas_sub[mod] = metas[mod].loc[cells_included]\n",
    "\n",
    "        # subsample gxc_hvftrs\n",
    "        if settings[mod].mod_category == 'mc':\n",
    "            gxc_hvftrs_sub[mod] = gxc_hvftrs[mod][cells_included]\n",
    "            print(mod, metas_sub[mod].shape, gxc_hvftrs_sub[mod].shape, time.time()-ti)\n",
    "            continue\n",
    "\n",
    "        cells_included_idx = snmcseq_utils.get_index_from_array(gxc_hvftrs[mod].cell, cells_included)\n",
    "        gxc_hvftrs_sub[mod] = GC_matrix(\n",
    "                                        gxc_hvftrs[mod].gene,\n",
    "                                        cells_included,\n",
    "                                        gxc_hvftrs[mod].data.tocsc()[:, cells_included_idx],\n",
    "                                        )\n",
    "        print(mod, metas_sub[mod].shape, gxc_hvftrs_sub[mod].data.shape, time.time()-ti)\n",
    "    return metas_sub, gxc_hvftrs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample cells\n",
    "p = 1\n",
    "\n",
    "if p < 1:\n",
    "    metas_sub, gxc_hvftrs_sub = subsampling(mods_selected, metas, gxc_hvftrs, p)\n",
    "else:\n",
    "    metas_sub = metas\n",
    "    gxc_hvftrs_sub = gxc_hvftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782 2417\n",
      "snmcseq_gene (1782, 4936) (2417, 4936) 0.6194031238555908\n",
      "1684 1998\n",
      "smarter_cells (1684, 6244) (1998, 6244) 0.6598730087280273\n",
      "1525 1769\n",
      "smarter_nuclei (1525, 5911) (1769, 5911) 0.7176680564880371\n"
     ]
    }
   ],
   "source": [
    "# split features metas_sub, gxc_hvftrs_sub_g0, gxc_hvftrs_sub_g1\n",
    "\n",
    "gxc_hvftrs_sub_g0 = collections.OrderedDict()\n",
    "gxc_hvftrs_sub_g1 = collections.OrderedDict()\n",
    "for mod in mods_selected: \n",
    "    # split gxc_hvftrs\n",
    "    if settings[mod].mod_category == 'mc':\n",
    "        _genes = gxc_hvftrs_sub[mod].index.values\n",
    "        _lookup = gene_set_lookup.reindex(_genes).fillna(-1).values\n",
    "        _genes_set0 = _genes[_lookup == 0]\n",
    "        _genes_set1 = _genes[_lookup == 1]\n",
    "        print(len(_genes_set0), len(_genes_set1))\n",
    "        gxc_hvftrs_sub_g0[mod] = gxc_hvftrs_sub[mod].loc[_genes_set0]\n",
    "        gxc_hvftrs_sub_g1[mod] = gxc_hvftrs_sub[mod].loc[_genes_set1]\n",
    "        \n",
    "        print(mod, gxc_hvftrs_sub_g0[mod].shape, gxc_hvftrs_sub_g1[mod].shape, time.time()-ti)\n",
    "        continue\n",
    "        \n",
    "    _genes = gxc_hvftrs_sub[mod].gene\n",
    "    _lookup = gene_set_lookup.reindex(_genes).fillna(-1).values\n",
    "    _genes_set0 = _genes[_lookup == 0]\n",
    "    _genes_set0_index = snmcseq_utils.get_index_from_array(_genes, _genes_set0)\n",
    "    _genes_set1 = _genes[_lookup == 1]\n",
    "    _genes_set1_index = snmcseq_utils.get_index_from_array(_genes, _genes_set1)\n",
    "    print(len(_genes_set0), len(_genes_set1))\n",
    "    gxc_hvftrs_sub_g0[mod] = GC_matrix(\n",
    "                                _genes_set0,\n",
    "                                gxc_hvftrs_sub[mod].cell,\n",
    "                                gxc_hvftrs_sub[mod].data.tocsr()[_genes_set0_index,:],\n",
    "                                )\n",
    "    gxc_hvftrs_sub_g1[mod] = GC_matrix(\n",
    "                                _genes_set1,\n",
    "                                gxc_hvftrs_sub[mod].cell,\n",
    "                                gxc_hvftrs_sub[mod].data.tocsr()[_genes_set1_index,:],\n",
    "                                )\n",
    "    \n",
    "    print(mod, gxc_hvftrs_sub_g0[mod].data.shape, gxc_hvftrs_sub_g1[mod].data.shape, time.time()-ti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "1snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "2snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "3snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "4snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "6snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "8snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "12snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "16snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "20snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "198.1137981414795\n"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "\n",
    "resolutions = [0.5, 1, 2, 3, 4, 6, 8, 12, 16, 20]\n",
    "(\n",
    " res_nclsts, \n",
    " res_mse_mean, res_mse_se, \n",
    " res_mse_t_mean, res_mse_t_se, \n",
    ") = nfoldcv_scf(\n",
    "            gxc_hvftrs_sub_g1, gxc_hvftrs_sub_g0, resolutions, k, \n",
    "            metas_sub, mods_selected, features_selected, settings,   \n",
    "            ps, drop_npcs,\n",
    "            cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "            npc,\n",
    "            output_pcX_all, output_cells_all, output_clst_and_umap,\n",
    "            reduce_dim=0,\n",
    "            nfolds=5, n_repeats=10)\n",
    "\n",
    "print(time.time() - ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "1snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "2snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "3snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "4snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "6snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "8snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "12snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "16snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "20snmcseq_gene\n",
      "..........\n",
      "smarter_cells\n",
      "..........\n",
      "smarter_nuclei\n",
      "..........\n",
      "184.52860379219055\n"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "\n",
    "resolutions = [0.5, 1, 2, 3, 4, 6, 8, 12, 16, 20]\n",
    "(\n",
    " res_nclsts, \n",
    " res_mse_mean, res_mse_se, \n",
    " res_mse_t_mean, res_mse_t_se, \n",
    ") = nfoldcv_scf_old(\n",
    "            gxc_hvftrs_sub_g1, gxc_hvftrs_sub_g0, resolutions, k, \n",
    "            metas_sub, mods_selected, features_selected, settings,   \n",
    "            ps, drop_npcs,\n",
    "            cross_mod_distance_measure, knn, relaxation, n_cca,\n",
    "            npc,\n",
    "            output_pcX_all, output_cells_all, output_clst_and_umap,\n",
    "            reduce_dim=0,\n",
    "            nfolds=5, n_repeats=10)\n",
    "\n",
    "print(time.time() - ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the objects:\n",
    "with open(output_results, 'wb') as f: \n",
    "    pickle.dump((\n",
    "                 res_nclsts, \n",
    "                 res_mse_mean, res_mse_se, \n",
    "                 res_mse_t_mean, res_mse_t_se, \n",
    "                ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting back the objects:\n",
    "with open(output_results, 'rb') as f: \n",
    "    (res_nclsts, \n",
    "     res_mse_mean, res_mse_se, \n",
    "     res_mse_t_mean, res_mse_t_se, \n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_figures.format('cluster_cv_sharey', 'pdf')\n",
    "n = len(mods_selected)\n",
    "nx = 3\n",
    "ny = int((n+nx-1)/nx)\n",
    "scale = 1\n",
    "fig, axs = plt.subplots(ny, nx, figsize=(5*nx*scale,4*ny*scale), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "for i, (mod, ax) in enumerate(zip(mods_selected, axs)):\n",
    "    base_level = np.min(res_mse_mean[mod])\n",
    "    if i % nx == 0:\n",
    "        ylabel = 'MSE +/- SEM\\n(normalized)'\n",
    "    else:\n",
    "        ylabel = ''\n",
    "    xlabel = ''\n",
    "    plot_bi_cv_subfig(ax, res_nclsts, \n",
    "                      res_mse_mean[mod]/base_level, res_mse_se[mod]/base_level, \n",
    "                      res_mse_t_mean[mod]/base_level, res_mse_t_se[mod]/base_level, \n",
    "                      settings[mod].color, mod, \n",
    "                      xlabel=xlabel,\n",
    "                      ylabel=ylabel\n",
    "                     )\n",
    "    ax.yaxis.set_major_locator(mtick.MaxNLocator(4))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, bottom=0.15)\n",
    "fig.text(0.5, 0, 'Number of clusters', ha='center', fontsize=15)\n",
    "fig.savefig(output, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_figures.format('cluster_cv_nosharey', 'pdf')\n",
    "n = len(mods_selected)\n",
    "nx = 3\n",
    "ny = int((n+nx-1)/nx)\n",
    "scale = 1\n",
    "fig, axs = plt.subplots(ny, nx, figsize=(5*nx*scale,4*ny*scale), sharex=True, sharey=False)\n",
    "axs = axs.flatten()\n",
    "for i, (mod, ax) in enumerate(zip(mods_selected, axs)):\n",
    "    base_level = np.min(res_mse_mean[mod])\n",
    "    if i % nx == 0:\n",
    "        ylabel = 'MSE +/- SEM\\n(normalized)'\n",
    "    else:\n",
    "        ylabel = ''\n",
    "    xlabel = ''\n",
    "    plot_bi_cv_subfig(ax, res_nclsts, \n",
    "                      res_mse_mean[mod]/base_level, res_mse_se[mod]/base_level, \n",
    "                      res_mse_t_mean[mod]/base_level, res_mse_t_se[mod]/base_level, \n",
    "                      settings[mod].color, mod, \n",
    "                      xlabel=xlabel,\n",
    "                      ylabel=ylabel\n",
    "                     )\n",
    "    ax.yaxis.set_major_locator(mtick.MaxNLocator(4))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.3, bottom=0.15)\n",
    "fig.text(0.5, 0, 'Number of clusters', ha='center', fontsize=15)\n",
    "fig.savefig(output, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
